{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77b344ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in a:\\new folder (2)\\lib\\site-packages (2.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e22003db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.14.0-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Requirement already satisfied: tensorflow-intel==2.14.0 in a:\\new folder (2)\\lib\\site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.24.3)\n",
      "Requirement already satisfied: six>=1.12.0 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.4.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: setuptools in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (65.6.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.58.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: packaging in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (22.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in a:\\new folder (2)\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in a:\\new folder (2)\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in a:\\new folder (2)\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in a:\\new folder (2)\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in a:\\new folder (2)\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in a:\\new folder (2)\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in a:\\new folder (2)\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in a:\\new folder (2)\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.23.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in a:\\new folder (2)\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in a:\\new folder (2)\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in a:\\new folder (2)\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3>=2.0.5 in a:\\new folder (2)\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.5)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in a:\\new folder (2)\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in a:\\new folder (2)\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in a:\\new folder (2)\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in a:\\new folder (2)\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in a:\\new folder (2)\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in a:\\new folder (2)\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in a:\\new folder (2)\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.2.2)\n",
      "Installing collected packages: tensorflow\n",
      "Successfully installed tensorflow-2.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "680f6587",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.preprocessing import image\n",
    "# from keras.utils import layer_utils\n",
    "# from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "# from keras.applications.imagenet_utils import _obtain_input_shape # this will work for older versions of keras. 2.2.0 or before\n",
    "# from keras.engine.topology import get_source_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35a51ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGGupdated(input_tensor=None,classes=2):    \n",
    "   \n",
    "    img_rows, img_cols = 300, 300   \n",
    "    img_channels = 3\n",
    "\n",
    "    img_dim = (img_rows, img_cols, img_channels)\n",
    "   \n",
    "    img_input = Input(shape=img_dim)\n",
    "    \n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3conv2')(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    \n",
    "    \n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "  \n",
    "   \n",
    "     \n",
    "    model = Model(inputs = img_input, outputs = x, name='VGGdemo')\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdc33411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d787435",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=VGGupdated(classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd305300",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91791dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bedroom', 'dining room']\n",
      "Types of rooms found:  2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "dataset_path = os.listdir('rooms_dataset')\n",
    "\n",
    "room_types = os.listdir('rooms_dataset')\n",
    "print (room_types)  \n",
    "\n",
    "print(\"Types of rooms found: \", len(dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9869298f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bedroom', 'rooms_dataset/bedroom/download (1).jpeg'), ('bedroom', 'rooms_dataset/bedroom/download (10).jpeg'), ('bedroom', 'rooms_dataset/bedroom/download (11).jpeg'), ('bedroom', 'rooms_dataset/bedroom/download (2).jpeg'), ('bedroom', 'rooms_dataset/bedroom/download (3).jpeg'), ('bedroom', 'rooms_dataset/bedroom/download (4).jpeg'), ('bedroom', 'rooms_dataset/bedroom/download (5).jpeg'), ('bedroom', 'rooms_dataset/bedroom/download (6).jpeg'), ('bedroom', 'rooms_dataset/bedroom/download (7).jpeg'), ('bedroom', 'rooms_dataset/bedroom/download (8).jpeg'), ('bedroom', 'rooms_dataset/bedroom/download (9).jpeg'), ('bedroom', 'rooms_dataset/bedroom/download.jpeg'), ('bedroom', 'rooms_dataset/bedroom/images (1).jpeg'), ('bedroom', 'rooms_dataset/bedroom/images (2).jpeg'), ('bedroom', 'rooms_dataset/bedroom/images (3).jpeg'), ('bedroom', 'rooms_dataset/bedroom/images (4).jpeg'), ('bedroom', 'rooms_dataset/bedroom/images (5).jpeg'), ('bedroom', 'rooms_dataset/bedroom/images (6).jpeg'), ('bedroom', 'rooms_dataset/bedroom/images.jpeg'), ('bedroom', 'rooms_dataset/bedroom/imagessss.jpeg'), ('dining room', 'rooms_dataset/dining room/download (1).jpeg'), ('dining room', 'rooms_dataset/dining room/download (10).jpeg'), ('dining room', 'rooms_dataset/dining room/download (11).jpeg'), ('dining room', 'rooms_dataset/dining room/download (12).jpeg'), ('dining room', 'rooms_dataset/dining room/download (13).jpeg'), ('dining room', 'rooms_dataset/dining room/download (14).jpeg'), ('dining room', 'rooms_dataset/dining room/download (15).jpeg'), ('dining room', 'rooms_dataset/dining room/download (16).jpeg'), ('dining room', 'rooms_dataset/dining room/download (17).jpeg'), ('dining room', 'rooms_dataset/dining room/download (18).jpeg'), ('dining room', 'rooms_dataset/dining room/download (2).jpeg'), ('dining room', 'rooms_dataset/dining room/download (3).jpeg'), ('dining room', 'rooms_dataset/dining room/download (4).jpeg'), ('dining room', 'rooms_dataset/dining room/download (5).jpeg'), ('dining room', 'rooms_dataset/dining room/download (6).jpeg'), ('dining room', 'rooms_dataset/dining room/download (7).jpeg'), ('dining room', 'rooms_dataset/dining room/download (8).jpeg'), ('dining room', 'rooms_dataset/dining room/download (9).jpeg'), ('dining room', 'rooms_dataset/dining room/download.jpeg'), ('dining room', 'rooms_dataset/dining room/images.jpeg')]\n"
     ]
    }
   ],
   "source": [
    "rooms = []\n",
    "\n",
    "for item in room_types:\n",
    "    all_rooms = os.listdir('rooms_dataset' + '/' +item)\n",
    " #print(all_shoes)\n",
    "\n",
    " # Add them to the list\n",
    "    for room in all_rooms:\n",
    "        rooms.append((item, str('rooms_dataset' + '/' +item) + '/' + room))\n",
    "print(rooms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c573be9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  room type                                     image\n",
      "0   bedroom   rooms_dataset/bedroom/download (1).jpeg\n",
      "1   bedroom  rooms_dataset/bedroom/download (10).jpeg\n",
      "2   bedroom  rooms_dataset/bedroom/download (11).jpeg\n",
      "3   bedroom   rooms_dataset/bedroom/download (2).jpeg\n",
      "4   bedroom   rooms_dataset/bedroom/download (3).jpeg\n"
     ]
    }
   ],
   "source": [
    "rooms_df = pd.DataFrame(data=rooms, columns=['room type', 'image'])\n",
    "print(rooms_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c98e0dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of rooms in the dataset:  40\n",
      "rooms in each category: \n",
      "bedroom        20\n",
      "dining room    20\n",
      "Name: room type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of rooms in the dataset: \", len(rooms_df))\n",
    "\n",
    "room_count = rooms_df['room type'].value_counts()\n",
    "\n",
    "print(\"rooms in each category: \")\n",
    "print(room_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a2e0957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in a:\\new folder (2)\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.19.3 in a:\\new folder (2)\\lib\\site-packages (from opencv-python) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76c5308f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    "path='rooms_dataset/'\n",
    "\n",
    "im_size=300\n",
    "\n",
    "images=[]\n",
    "labels=[]\n",
    "\n",
    "for i in room_types:\n",
    "    data_path=path+str(i)\n",
    "    filenames=[i for i in os.listdir(data_path)]\n",
    "    \n",
    "    for f in filenames:\n",
    "        img=cv2.imread(data_path+'/'+f)\n",
    "        img=cv2.resize(img,(im_size,im_size))\n",
    "        images.append(img)\n",
    "        labels.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0956f707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 300, 300, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = np.array(images)\n",
    "\n",
    "images = images.astype('float32') / 255.0\n",
    "images.shape  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47c0aa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder , OneHotEncoder\n",
    "y=rooms_df['room type'].values\n",
    "\n",
    "\n",
    "y_labelencoder = LabelEncoder ()\n",
    "y = y_labelencoder.fit_transform (y)\n",
    "print (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc1a318f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "y = y.reshape(-1, 1)\n",
    "\n",
    "\n",
    "onehotencoder = OneHotEncoder()\n",
    "\n",
    "\n",
    "Y = onehotencoder.fit_transform(y).toarray()\n",
    "\n",
    "\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6da20258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38, 300, 300, 3)\n",
      "(2, 300, 300, 3)\n",
      "(38, 2)\n",
      "(2, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "images,Y=shuffle(images,Y,random_state=1)\n",
    "\n",
    "x_train,x_test,y_train,y_test=train_test_split(images,Y,test_size=0.05,random_state=415)\n",
    "\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26aebcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,epochs=10,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10604105",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds=model.evaluate(te)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
